#!/usr/bin/env python3
"""
flow_receiver.py
Flow ìˆ˜ì‹  & ìë™ ë°©ì–´ (ë©”ì¸ ì‹œìŠ¤í…œ)
í¬íŠ¸: 5001
"""

from flask import Flask, request, jsonify
import joblib
import requests
import json
import logging
import numpy as np
from threading import Lock

app = Flask(__name__)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('flow_receiver.log'),
        logging.StreamHandler()
    ]
)

# ì„¤ì •
DEVICE1_RULE_CLIENT = 'http://192.168.0.42:10002'
OLLAMA_URL = 'http://localhost:11434/api/generate'
OLLAMA_MODEL = 'qwen2.5:7b'

# ì „ì—­ ë³€ìˆ˜
current_sid = 900000001
sid_lock = Lock()

# ML ëª¨ë¸ ë¡œë“œ
try:
    model = joblib.load('models/random_forest_model.joblib')
    scaler = joblib.load('models/min_max_scaler.joblib')
    le = joblib.load('models/label_encoder.joblib')
    feature_names = joblib.load('models/feature_names.joblib')
    
    logging.info("âœ… ML ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    logging.info(f"   - Feature ê°œìˆ˜: {len(feature_names)}")
    logging.info(f"   - í´ë˜ìŠ¤ ê°œìˆ˜: {len(le.classes_)}")

except Exception as e:
    logging.error(f"âŒ ML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    model = None


def get_next_sid():
    """Thread-safe SID ìƒì„±"""
    global current_sid
    with sid_lock:
        sid = current_sid
        current_sid += 1
        return sid


def convert_to_77_features(flow_data):
    """
    13ê°œ Flow Feature â†’ 77ê°œ ML Feature ë³€í™˜
    
    Args:
        flow_data (dict): Flow ë°ì´í„° (13ê°œ)
    
    ë°˜í™˜:
        list: 77ê°œ Feature ê°’
    """
    total_packets = flow_data['pkts_toserver'] + flow_data['pkts_toclient']
    total_bytes = flow_data['bytes_toserver'] + flow_data['bytes_toclient']
    flow_age = max(flow_data['flow_age'], 1)  # 0 ë°©ì§€
    
    # ê¸°ë³¸ Feature ê³„ì‚°
    features_dict = {
        "Flow_Duration": flow_age * 1_000_000,  # ë§ˆì´í¬ë¡œì´ˆ
        "Total_Fwd_Packets": flow_data['pkts_toserver'],
        "Total_Backward_Packets": flow_data['pkts_toclient'],
        "Total_Length_of_Fwd_Packets": flow_data['bytes_toserver'],
        "Total_Length_of_Bwd_Packets": flow_data['bytes_toclient'],
        "Flow_Bytes_s": total_bytes / flow_age,
        "Flow_Packets_s": total_packets / flow_age,
        "Flow_IAT_Mean": (flow_age * 1_000_000) / max(total_packets, 1),
        "Fwd_IAT_Mean": (flow_age * 1_000_000) / max(flow_data['pkts_toserver'], 1),
        "Bwd_IAT_Mean": (flow_age * 1_000_000) / max(flow_data['pkts_toclient'], 1),
        "Fwd_Packet_Length_Mean": flow_data['bytes_toserver'] / max(flow_data['pkts_toserver'], 1),
        "Bwd_Packet_Length_Mean": flow_data['bytes_toclient'] / max(flow_data['pkts_toclient'], 1),
        "Packet_Length_Mean": total_bytes / max(total_packets, 1),
        "Packet_Length_Std": 0.0,  # ë‹¨ìˆœí™”
        "Packet_Length_Variance": 0.0,
        "Average_Packet_Size": total_bytes / max(total_packets, 1),
        "Fwd_Header_Length": flow_data['pkts_toserver'] * 20,  # ì¶”ì •
        "Bwd_Header_Length": flow_data['pkts_toclient'] * 20,
    }
    
    # ë‚˜ë¨¸ì§€ FeatureëŠ” 0.0ìœ¼ë¡œ ì´ˆê¸°í™”
    for fname in feature_names:
        if fname not in features_dict:
            features_dict[fname] = 0.0
    
    # Feature ìˆœì„œëŒ€ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    return [features_dict[fname] for fname in feature_names]


def predict_attack(flow_data):
    """
    ML ëª¨ë¸ë¡œ ê³µê²© ì˜ˆì¸¡
    
    Args:
        flow_data (dict): Flow ë°ì´í„°
    
    ë°˜í™˜:
        dict: ì˜ˆì¸¡ ê²°ê³¼
    """
    if model is None:
        return {
            'is_malicious': False,
            'attack_type': 'UNKNOWN',
            'confidence': 0.0,
            'error': 'Model not loaded'
        }
    
    try:
        # Feature ë³€í™˜
        features = convert_to_77_features(flow_data)
        
        # Infinity/NaN ì²˜ë¦¬
        features = [0.0 if (np.isnan(f) or np.isinf(f)) else f for f in features]
        
        # ìŠ¤ì¼€ì¼ë§
        X_scaled = scaler.transform([features])
        
        # ì˜ˆì¸¡
        prediction = model.predict(X_scaled)[0]
        predicted_label = le.inverse_transform([prediction])[0]
        
        # ì‹ ë¢°ë„
        probabilities = model.predict_proba(X_scaled)[0]
        confidence = probabilities.max()
        
        is_malicious = (predicted_label != 'BENIGN')
        
        return {
            'is_malicious': is_malicious,
            'attack_type': predicted_label,
            'confidence': float(confidence)
        }
    
    except Exception as e:
        logging.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return {
            'is_malicious': False,
            'attack_type': 'ERROR',
            'confidence': 0.0,
            'error': str(e)
        }


def generate_suricata_rule(attack_type, flow_data):
    """
    Ollama (Qwen 2.5)ë¡œ Suricata ë£° ìƒì„±
    
    Args:
        attack_type (str): ê³µê²© ìœ í˜•
        flow_data (dict): Flow ë°ì´í„°
    
    ë°˜í™˜:
        str: Suricata ë£°
    """
    sid = get_next_sid()
    
    # ê³µê²© ìœ í˜•ë³„ íŒíŠ¸
    hints = {
        'DDoS': 'Use threshold option: type both, track by_src, count 100, seconds 1',
        'PortScan': 'Use threshold option: type both, track by_src, count 50, seconds 1',
        'Web Attack': 'Use content option for HTTP detection, port 80 or 443',
        'Bot': 'Detect C&C communication patterns',
        'DoS': 'Use threshold for rate limiting'
    }
    
    hint = hints.get(attack_type, 'Create appropriate detection rule')
    
    prompt = f"""You are a Suricata IDS expert. Generate ONE line rule ONLY.

Attack Information:
- Type: {attack_type}
- Source IP: {flow_data['src_ip']}
- Destination IP: {flow_data['dest_ip']}
- Protocol: {flow_data['proto']}
- Hint: {hint}

Requirements:
1. Output ONLY the rule (one line, no explanation)
2. Format: drop tcp $EXTERNAL_NET any -> $HOME_NET any (msg:"AI_BLOCK:{attack_type}"; sid:{sid}; rev:1;)
3. Use appropriate options for {attack_type}
4. Do NOT include markdown, backticks, or any other text

Rule:"""
    
    try:
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "top_p": 0.9
                }
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            generated_text = result.get('response', '').strip()
            
            # ë£° ì¶”ì¶œ (ì²« ë²ˆì§¸ ìœ íš¨í•œ ë£°ë§Œ)
            for line in generated_text.split('\n'):
                line = line.strip()
                if line.startswith(('drop', 'alert', 'reject', 'pass')):
                    # ë°±í‹± ì œê±°
                    line = line.replace('```', '').strip()
                    
                    # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
                    if not line.endswith(';'):
                        line += ';'
                    
                    return line, sid
            
            # ìœ íš¨í•œ ë£°ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ ë£°
            default_rule = f'drop tcp {flow_data["src_ip"]} any -> $HOME_NET any (msg:"AI_BLOCK:{attack_type}"; sid:{sid}; rev:1;)'
            logging.warning(f"ìœ íš¨í•œ ë£° ë¯¸ìƒì„±, ê¸°ë³¸ ë£° ì‚¬ìš©")
            return default_rule, sid
        
        else:
            logging.error(f"Ollama ì˜¤ë¥˜: {response.status_code}")
            return None, sid
    
    except Exception as e:
        logging.error(f"ë£° ìƒì„± ì‹¤íŒ¨: {e}")
        return None, sid


def apply_rule_to_device1(rule, sid):
    """
    ìƒì„±ëœ ë£°ì„ ì¥ì¹˜ 1ì— ì ìš©
    
    Args:
        rule (str): Suricata ë£°
        sid (int): ë£° ID
    
    ë°˜í™˜:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        response = requests.post(
            DEVICE1_RULE_CLIENT,
            json={
                "type": "ADD_RULE",
                "rule": rule,
                "sid": sid
            },
            timeout=5
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get('return') == 'OK':
                logging.info(f"âœ… ë£° ì ìš© ì™„ë£Œ: SID {sid}")
                return True
            else:
                logging.error(f"âŒ ë£° ì ìš© ì‹¤íŒ¨: {result.get('message')}")
                return False
        else:
            logging.error(f"âŒ ì¥ì¹˜ 1 ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    
    except Exception as e:
        logging.error(f"âŒ ë£° ì ìš© ì˜¤ë¥˜: {e}")
        return False


@app.route('/health', methods=['GET'])
def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        'status': 'healthy',
        'service': 'flow_receiver',
        'port': 5001,
        'model_loaded': model is not None
    })


@app.route('/receive-flow', methods=['POST'])
def receive_flow():
    """
    ì¥ì¹˜ 1ë¡œë¶€í„° Flow ìˆ˜ì‹  ë° ì²˜ë¦¬
    
    POST /receive-flow
    Body: Flow ë°ì´í„° (JSON)
    """
    flow_data = request.json
    
    if not flow_data:
        return jsonify({'error': 'No data'}), 400
    
    src_ip = flow_data.get('src_ip', 'unknown')
    dest_ip = flow_data.get('dest_ip', 'unknown')
    
    # 1. ML ì˜ˆì¸¡
    prediction = predict_attack(flow_data)
    
    if prediction['is_malicious']:
        attack_type = prediction['attack_type']
        confidence = prediction['confidence']
        
        logging.warning(
            f"ğŸš¨ ì•…ì„± íƒì§€! {attack_type} (ì‹ ë¢°ë„: {confidence:.2%}) "
            f"- {src_ip} â†’ {dest_ip}"
        )
        
        # 2. Ollama ë£° ìƒì„±
        logging.info(f"ğŸ“ Suricata ë£° ìƒì„± ì¤‘...")
        rule, sid = generate_suricata_rule(attack_type, flow_data)
        
        if rule:
            logging.info(f"âœ“ ë£° ìƒì„± ì™„ë£Œ: {rule[:80]}...")
            
            # 3. ì¥ì¹˜ 1ì— ì ìš©
            success = apply_rule_to_device1(rule, sid)
            
            return jsonify({
                'is_malicious': True,
                'attack_type': attack_type,
                'confidence': confidence,
                'rule_generated': True,
                'rule': rule,
                'sid': sid,
                'rule_applied': success
            })
        else:
            logging.error(f"âŒ ë£° ìƒì„± ì‹¤íŒ¨")
            return jsonify({
                'is_malicious': True,
                'attack_type': attack_type,
                'confidence': confidence,
                'rule_generated': False,
                'error': 'Rule generation failed'
            })
    
    else:
        # ì •ìƒ íŠ¸ë˜í”½
        return jsonify({
            'is_malicious': False,
            'attack_type': 'BENIGN'
        })


if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ›¡ï¸ Flow Receiver & ìë™ ë°©ì–´ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print(f"ğŸ“¡ í¬íŠ¸: 5001")
    print(f"ğŸ¤– ML ëª¨ë¸: {'âœ… ë¡œë“œë¨' if model else 'âŒ ì—†ìŒ'}")
    print(f"ğŸ§  Ollama: {OLLAMA_URL}")
    print(f"   ëª¨ë¸: {OLLAMA_MODEL}")
    print(f"ğŸ¯ ì¥ì¹˜ 1: {DEVICE1_RULE_CLIENT}")
    print("=" * 60)
    print("âœ… ëŒ€ê¸° ì¤‘...\n")
    
    app.run(host='0.0.0.0', port=5001, debug=False)